{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_prefix = '.'\n",
    "\n",
    "def save_to(df, file_name):\n",
    "    df.to_csv(loc_prefix + '/data/' + file_name, index=False)\n",
    "def read_csv(file_name):\n",
    "    return pd.read_csv(loc_prefix + '/data/' + file_name)\n",
    "\n",
    "def read_train_test(rel_path_train, rel_path_test):\n",
    "    dfs = []\n",
    "    for path in [rel_path_train, rel_path_test]:\n",
    "        df = read_csv(path)\n",
    "        print(f'{path} {df.shape}')\n",
    "        display(df.head(5))\n",
    "        \n",
    "        dfs.append(df)\n",
    "    \n",
    "    return dfs[0], dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/train.csv (27643, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Page content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt; &lt;span c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Popularity                                       Page content\n",
       "0   0          -1  <html><head><div class=\"article-info\"> <span c...\n",
       "1   1           1  <html><head><div class=\"article-info\"><span cl...\n",
       "2   2           1  <html><head><div class=\"article-info\"><span cl...\n",
       "3   3          -1  <html><head><div class=\"article-info\"><span cl...\n",
       "4   4          -1  <html><head><div class=\"article-info\"><span cl..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/test.csv (11847, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Page content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27643</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27644</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27645</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27646</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27647</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id                                       Page content\n",
       "0  27643  <html><head><div class=\"article-info\"><span cl...\n",
       "1  27644  <html><head><div class=\"article-info\"><span cl...\n",
       "2  27645  <html><head><div class=\"article-info\"><span cl...\n",
       "3  27646  <html><head><div class=\"article-info\"><span cl...\n",
       "4  27647  <html><head><div class=\"article-info\"><span cl..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_train = pd.read_csv('./data/train.csv')\n",
    "# df_test = pd.read_csv('./data/test.csv')\n",
    "# print(df.shape)\n",
    "# display(df.head(5))\n",
    "\n",
    "df_train, df_test = read_train_test('train/train.csv', 'test/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    # remove HTML tags\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    \n",
    "    # regex for matching emoticons, keep emoticons, ex: :), :-P, :-D\n",
    "    r = '(?::|;|=|X)(?:-)?(?:\\)|\\(|D|P)'\n",
    "    emoticons = re.findall(r, text)\n",
    "    text = re.sub(r, '', text)\n",
    "    \n",
    "    # convert to lowercase and append all emoticons behind (with space in between)\n",
    "    # replace('-','') removes nose of emoticons\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-','')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_attribute(df):\n",
    "    df_new = df\n",
    "    \n",
    "    channels = []\n",
    "    titles = []\n",
    "    raw_contents = []\n",
    "    content_lens = []\n",
    "    avg_word_lens = []\n",
    "    topics = []\n",
    "    unique_topics = []\n",
    "    authors = []\n",
    "    times = []\n",
    "    count = 0\n",
    "    # get_text = lambda tags: [for t in tags: t.get_text()]\n",
    "    df = df.loc[:, ]\n",
    "    for row in df.loc[:, 'Page content']:\n",
    "        soup = BeautifulSoup(row, 'html.parser')\n",
    "\n",
    "        # data-channel\n",
    "        data_channel = soup.article\n",
    "        if data_channel != None:\n",
    "#             print(data_channel['data-channel'])\n",
    "            data_channel = data_channel['data-channel']\n",
    "        else:\n",
    "            data_channel = 'None'\n",
    "        channels.append(data_channel)\n",
    "\n",
    "        # title\n",
    "        title = soup.select_one('h1.title').text\n",
    "        titles.append(title)\n",
    "\n",
    "        # raw content\n",
    "        content = soup.select_one('.article-content').text\n",
    "        raw_contents.append(content)\n",
    "\n",
    "        # content length\n",
    "        content_len = len(content.split(' '))\n",
    "        content_lens.append(content_len)\n",
    "\n",
    "        # avg word length\n",
    "        content_words = content.split(' ')\n",
    "        word_lens = [len(word) for word in content_words if len(word) > 0]\n",
    "        # print(content_words)\n",
    "        # print(word_lens)\n",
    "        avg_word_len = sum(word_lens) / (len(word_lens) + 1e-9)\n",
    "        avg_word_lens.append(avg_word_len)\n",
    "\n",
    "        # topic\n",
    "        topic_arr = [t.get_text().lower() for t in soup.footer.find_all('a')]\n",
    "        topic = ','.join(topic_arr)\n",
    "        topics.append(topic)\n",
    "        unique_topics.extend(topic_arr)\n",
    "\n",
    "        # author\n",
    "        author = soup.select_one('.author_name')\n",
    "        if author != None:\n",
    "            author = author.a\n",
    "            if author != None:\n",
    "                author = author['href']\n",
    "                if author != None:\n",
    "                    author = author.split('/')[-2]\n",
    "        authors.append(author)\n",
    "\n",
    "        # time\n",
    "        time = soup.time\n",
    "        if time != None and time.has_attr('datetime'):\n",
    "            time = time['datetime']\n",
    "            if time != None:\n",
    "                time = datetime.strptime(time, '%a, %d %b %Y %H:%M:%S %z')\n",
    "                if time != None:\n",
    "                    time = [time.year, time.month, time.day, time.hour, time.minute, time.second]\n",
    "                else:\n",
    "                    time = [0, 0, 0, 0, 0, 0]\n",
    "            else:\n",
    "                time = [0, 0, 0, 0, 0, 0]\n",
    "        else:\n",
    "            time = [0, 0, 0, 0, 0, 0]\n",
    "            \n",
    "        times.append(time)\n",
    "\n",
    "        if(not count % 1000):\n",
    "            print(f'Parse Progress: {count} th')\n",
    "        count = count + 1\n",
    "\n",
    "    unique_topics = np.unique(unique_topics)\n",
    "    print(f'Unique Topics {len(unique_topics)}')\n",
    "\n",
    "    df_new['data-channel'] = channels\n",
    "    df_new['title'] = titles\n",
    "    df_new['raw_content'] = raw_contents\n",
    "    df_new['content_length'] = content_lens\n",
    "    df_new['avg_word_length'] = avg_word_lens\n",
    "    df_new['topics'] = topics\n",
    "    df_new['author'] = authors\n",
    "    df_new[['year', 'month', 'day', 'hour', 'min', 'sec']] = times\n",
    "\n",
    "    print(f'Converted DF Shape: {df_new.shape}')\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train (27643, 3)\n",
      "Parse Progress: 0 th\n",
      "Parse Progress: 1000 th\n",
      "Parse Progress: 2000 th\n",
      "Parse Progress: 3000 th\n",
      "Parse Progress: 4000 th\n",
      "Parse Progress: 5000 th\n",
      "Parse Progress: 6000 th\n",
      "Parse Progress: 7000 th\n",
      "Parse Progress: 8000 th\n",
      "Parse Progress: 9000 th\n",
      "Parse Progress: 10000 th\n",
      "Parse Progress: 11000 th\n",
      "Parse Progress: 12000 th\n",
      "Parse Progress: 13000 th\n",
      "Parse Progress: 14000 th\n",
      "Parse Progress: 15000 th\n",
      "Parse Progress: 16000 th\n",
      "Parse Progress: 17000 th\n",
      "Parse Progress: 18000 th\n",
      "Parse Progress: 19000 th\n",
      "Parse Progress: 20000 th\n",
      "Parse Progress: 21000 th\n",
      "Parse Progress: 22000 th\n",
      "Parse Progress: 23000 th\n",
      "Parse Progress: 24000 th\n",
      "Parse Progress: 25000 th\n",
      "Parse Progress: 26000 th\n",
      "Parse Progress: 27000 th\n",
      "Unique Topics 14012\n",
      "Converted DF Shape: (27643, 16)\n",
      "df_test (11847, 2)\n",
      "Parse Progress: 0 th\n",
      "Parse Progress: 1000 th\n",
      "Parse Progress: 2000 th\n",
      "Parse Progress: 3000 th\n",
      "Parse Progress: 4000 th\n",
      "Parse Progress: 5000 th\n",
      "Parse Progress: 6000 th\n",
      "Parse Progress: 7000 th\n",
      "Parse Progress: 8000 th\n",
      "Parse Progress: 9000 th\n",
      "Parse Progress: 10000 th\n",
      "Parse Progress: 11000 th\n",
      "Unique Topics 8744\n",
      "Converted DF Shape: (11847, 15)\n"
     ]
    }
   ],
   "source": [
    "print(f'df_train {df_train.shape}')\n",
    "df_train = capture_attribute(df_train)\n",
    "print(f'df_test {df_test.shape}')\n",
    "df_test = capture_attribute(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train (27643, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Page content</th>\n",
       "      <th>data-channel</th>\n",
       "      <th>title</th>\n",
       "      <th>raw_content</th>\n",
       "      <th>content_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>topics</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt; &lt;span c...</td>\n",
       "      <td>world</td>\n",
       "      <td>NASA's Grand Challenge: Stop Asteroids From De...</td>\n",
       "      <td>There may be killer asteroids headed for Eart...</td>\n",
       "      <td>583</td>\n",
       "      <td>5.214905</td>\n",
       "      <td>asteroid,asteroids,challenge,earth,space,u.s.,...</td>\n",
       "      <td>None</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>tech</td>\n",
       "      <td>Google's New Open Source Patent Pledge: We Won...</td>\n",
       "      <td>Google took a stand of sorts against patent-l...</td>\n",
       "      <td>309</td>\n",
       "      <td>5.032787</td>\n",
       "      <td>apps and software,google,open source,opn pledg...</td>\n",
       "      <td>christina</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>Ballin': 2014 NFL Draft Picks Get to Choose Th...</td>\n",
       "      <td>You've spend countless hours training to be a...</td>\n",
       "      <td>1360</td>\n",
       "      <td>4.750225</td>\n",
       "      <td>entertainment,nfl,nfl draft,sports,television</td>\n",
       "      <td>sam-laird</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>watercooler</td>\n",
       "      <td>Cameraperson Fails Deliver Slapstick Laughs</td>\n",
       "      <td>Tired of the same old sports fails and ne...</td>\n",
       "      <td>476</td>\n",
       "      <td>4.841727</td>\n",
       "      <td>sports,video,videos,watercooler</td>\n",
       "      <td>sam-laird</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>NFL Star Helps Young Fan Prove Friendship With...</td>\n",
       "      <td>At 6-foot-5 and 298 pounds, All-Pro NFL star ...</td>\n",
       "      <td>1937</td>\n",
       "      <td>5.089650</td>\n",
       "      <td>entertainment,instagram,instagram video,nfl,sp...</td>\n",
       "      <td>connor-finnegan</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Popularity                                       Page content  \\\n",
       "0   0          -1  <html><head><div class=\"article-info\"> <span c...   \n",
       "1   1           1  <html><head><div class=\"article-info\"><span cl...   \n",
       "2   2           1  <html><head><div class=\"article-info\"><span cl...   \n",
       "3   3          -1  <html><head><div class=\"article-info\"><span cl...   \n",
       "4   4          -1  <html><head><div class=\"article-info\"><span cl...   \n",
       "\n",
       "    data-channel                                              title  \\\n",
       "0          world  NASA's Grand Challenge: Stop Asteroids From De...   \n",
       "1           tech  Google's New Open Source Patent Pledge: We Won...   \n",
       "2  entertainment  Ballin': 2014 NFL Draft Picks Get to Choose Th...   \n",
       "3    watercooler        Cameraperson Fails Deliver Slapstick Laughs   \n",
       "4  entertainment  NFL Star Helps Young Fan Prove Friendship With...   \n",
       "\n",
       "                                         raw_content  content_length  \\\n",
       "0   There may be killer asteroids headed for Eart...             583   \n",
       "1   Google took a stand of sorts against patent-l...             309   \n",
       "2   You've spend countless hours training to be a...            1360   \n",
       "3       Tired of the same old sports fails and ne...             476   \n",
       "4   At 6-foot-5 and 298 pounds, All-Pro NFL star ...            1937   \n",
       "\n",
       "   avg_word_length                                             topics  \\\n",
       "0         5.214905  asteroid,asteroids,challenge,earth,space,u.s.,...   \n",
       "1         5.032787  apps and software,google,open source,opn pledg...   \n",
       "2         4.750225      entertainment,nfl,nfl draft,sports,television   \n",
       "3         4.841727                    sports,video,videos,watercooler   \n",
       "4         5.089650  entertainment,instagram,instagram video,nfl,sp...   \n",
       "\n",
       "            author  year  month  day  hour  min  sec  \n",
       "0             None  2013      6   19    15    4   30  \n",
       "1        christina  2013      3   28    17   40   55  \n",
       "2        sam-laird  2014      5    7    19   15   20  \n",
       "3        sam-laird  2013     10   11     2   26   50  \n",
       "4  connor-finnegan  2014      4   17     3   31   43  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test (11847, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Page content</th>\n",
       "      <th>data-channel</th>\n",
       "      <th>title</th>\n",
       "      <th>raw_content</th>\n",
       "      <th>content_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>topics</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27643</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>Soccer Star Gets Twitter Death Threats After T...</td>\n",
       "      <td>Note to humanity: One Direction fandom ai...</td>\n",
       "      <td>622</td>\n",
       "      <td>5.220114</td>\n",
       "      <td>entertainment,music,one direction,soccer,sports</td>\n",
       "      <td>sam-laird</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27644</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>tech</td>\n",
       "      <td>Google Glass Gets an Accessory Store</td>\n",
       "      <td>Shortly after announcing a hardware upgrade f...</td>\n",
       "      <td>149</td>\n",
       "      <td>4.739437</td>\n",
       "      <td>gadgets,glass,google,google glass,google glass...</td>\n",
       "      <td>stan-schroeder</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27645</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>business</td>\n",
       "      <td>OUYA Gaming Console Already Sold Out on Amazon</td>\n",
       "      <td>Well, that was quick. Just hours after going ...</td>\n",
       "      <td>168</td>\n",
       "      <td>5.018293</td>\n",
       "      <td>amazon,amazon kindle,business,gaming</td>\n",
       "      <td>todd-wasserman</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27646</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>film</td>\n",
       "      <td>'Between Two Ferns' Mocks Oscar Nominees</td>\n",
       "      <td>Between Two Ferns: Oscar Buzz Edition Part 1...</td>\n",
       "      <td>162</td>\n",
       "      <td>5.581699</td>\n",
       "      <td>between two ferns,movies,the oscars,oscars 201...</td>\n",
       "      <td>neha-prakash</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27647</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>'American Sniper' Trailer: Looks Like Eastwood...</td>\n",
       "      <td>Ever since The Hurt Locker it seems like ...</td>\n",
       "      <td>225</td>\n",
       "      <td>5.041096</td>\n",
       "      <td>american sniper,awards,bradley cooper,clint ea...</td>\n",
       "      <td>josh-dickey</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id                                       Page content   data-channel  \\\n",
       "0  27643  <html><head><div class=\"article-info\"><span cl...  entertainment   \n",
       "1  27644  <html><head><div class=\"article-info\"><span cl...           tech   \n",
       "2  27645  <html><head><div class=\"article-info\"><span cl...       business   \n",
       "3  27646  <html><head><div class=\"article-info\"><span cl...           film   \n",
       "4  27647  <html><head><div class=\"article-info\"><span cl...  entertainment   \n",
       "\n",
       "                                               title  \\\n",
       "0  Soccer Star Gets Twitter Death Threats After T...   \n",
       "1               Google Glass Gets an Accessory Store   \n",
       "2     OUYA Gaming Console Already Sold Out on Amazon   \n",
       "3           'Between Two Ferns' Mocks Oscar Nominees   \n",
       "4  'American Sniper' Trailer: Looks Like Eastwood...   \n",
       "\n",
       "                                         raw_content  content_length  \\\n",
       "0       Note to humanity: One Direction fandom ai...             622   \n",
       "1   Shortly after announcing a hardware upgrade f...             149   \n",
       "2   Well, that was quick. Just hours after going ...             168   \n",
       "3    Between Two Ferns: Oscar Buzz Edition Part 1...             162   \n",
       "4       Ever since The Hurt Locker it seems like ...             225   \n",
       "\n",
       "   avg_word_length                                             topics  \\\n",
       "0         5.220114    entertainment,music,one direction,soccer,sports   \n",
       "1         4.739437  gadgets,glass,google,google glass,google glass...   \n",
       "2         5.018293               amazon,amazon kindle,business,gaming   \n",
       "3         5.581699  between two ferns,movies,the oscars,oscars 201...   \n",
       "4         5.041096  american sniper,awards,bradley cooper,clint ea...   \n",
       "\n",
       "           author  year  month  day  hour  min  sec  \n",
       "0       sam-laird  2013      9    9    19   47    2  \n",
       "1  stan-schroeder  2013     10   31     9   25    2  \n",
       "2  todd-wasserman  2013      6   25    12   54   54  \n",
       "3    neha-prakash  2013      2   13     3   30   21  \n",
       "4     josh-dickey  2014     10    3     1   34   54  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'df_train {df_train.shape}')\n",
    "display(df_train.head(5))\n",
    "print(f'df_test {df_test.shape}')\n",
    "display(df_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np_t = np.array(times)\n",
    "# print(np_t)\n",
    "# print(np_t.shape)\n",
    "# for i in range(np_t.shape[0]):\n",
    "#     np_t[i] = np.array(np_t[i])\n",
    "#     if np_t[i].shape[0] != 6:\n",
    "#         print(\"ERR\")\n",
    "#         df.loc[i, ['year', 'month', 'day', 'hour', 'min', 'sec']] = np.array([0, 0, 0, 0, 0, 0])\n",
    "#     else:\n",
    "#         df.loc[i, ['year', 'month', 'day', 'hour', 'min', 'sec']] = np_t[i]\n",
    "\n",
    "# print(np_t.shape)\n",
    "# print(np_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pp20/pp20s02/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/pp20/pp20s02/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['runner', 'like', 'run', 'thu', 'run']\n",
      "['runner', 'like', 'running', 'thus', 'run']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def tokenizer_stem_nostop(text):\n",
    "    porter = PorterStemmer()\n",
    "    return [porter.stem(w) for w in re.split('\\s+', text.strip()) \\\n",
    "            if w not in stop and re.match('[a-zA-Z]+', w)]\n",
    "\n",
    "def tokenizer_lemm_nostop(text):\n",
    "    lemm = WordNetLemmatizer()\n",
    "    return [lemm.lemmatize(w) for w in re.split('\\s+', text.strip()) \\\n",
    "            if w not in stop and re.match('[a-zA-Z]+', w)]\n",
    "\n",
    "print(tokenizer_stem_nostop('runners like running and thus they run'))\n",
    "print(tokenizer_lemm_nostop('runners like running and thus they run'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmed_nostop_page_data = []\n",
    "# for page in cleaned_page_data:\n",
    "#     stemmed_nostop_page_data.append(tokenizer_stem_nostop(page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to(df_test, 'test/feats_test.csv')\n",
    "save_to(df_train, 'train/feats_train.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
